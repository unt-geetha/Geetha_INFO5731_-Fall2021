{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-geetha/Geetha_INFO5731_-Fall2021/blob/main/Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87tJXrF7iQq3"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis, which entails identifying the sentiment or emotional tone expressed in a text, such as a product review, social media post, or customer feedback, is an engaging task for text classification. Businesses can benefit from sentiment analysis by using it to better understand customer opinions and make data-driven decisions. The following five feature types can be helpful in creating a sentiment analysis machine learning model:\n",
        "\n",
        "Words in a Bag (BoW):\n",
        "\n",
        "Features: Frequency counts of words. Justification: BoW uses word frequencies as a vector to represent the text. Through enumerating each word's occurrences, this feature can quantify the significance of particular phrases in conveying emotion. Terms such as \"disappointed\" or \"excellent\" have a powerful emotional impact. Term Frequency-Inverse Document Frequency, or TF-IDF:\n",
        "\n",
        "Features: word TF-IDF scores. To explain, TF-IDF considers a word's relevance throughout the entire dataset in addition to its frequency in a given document. Words that are more specific to a document and, thus, more expressive of sentiment can be found using this function. Word Embeddings (such as GloVe and Word2Vec):\n",
        "\n",
        "Features: Word representations in vector format. Reason: Word embeddings record the semantic connections between words. The model can comprehend the context and meaning of words by employing pretrained word vectors, which is essential for recognizing subtle emotions and comprehending synonyms and related phrases. Tags for Part-of-Speech (POS):\n",
        "\n",
        "Features: POS labels for textual words. Explanation: POS tags give details about each word's function in a sentence's grammar. Sentiment frequently depends on sentence structure, therefore understanding a sentence's structure through POS tags can aid in differentiating between positive and negative sentiment. N-Grams\n",
        "\n",
        "Features: n-word sequences that follow one another. Interpretation: N-grams depict the environment in which words are found. Trigrams (three word sequences) and bigrams (two word sequences) might assist the model in determining particular word combinations that convey emotion. When taken as a whole, terms like \"not good\" or \"very happy\" can more correctly express sentiment."
      ],
      "metadata": {
        "id": "eThzSL1biSW_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSkng_TJiQq5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFlEaqMkiQq6"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pdceN6piQq6",
        "outputId": "b6772de7-10ae-4430-c2e7-e658fee9f71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original DataFrame:\n",
            "                                                  Text\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n\n",
            "1                                 1having to do with\\n\n",
            "2    a POIGANT story about a young man who goes off...\n",
            "3                                 Synonyms for about\\n\n",
            "4                                                   \\n\n",
            "..                                                 ...\n",
            "117                                                 \\n\n",
            "118  asleep, dormant, dozing, napping, resting, sle...\n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...\n",
            "120                                      dreaming ME\\n\n",
            "121                             hypnotized, MESMERIZED\n",
            "\n",
            "[122 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store the decoded data\n",
        "geetha_list = []\n",
        "\n",
        "# Local path to the data file\n",
        "file_path = \"C:\\\\Users\\\\Harilal\\\\Desktop\\\\Synonyms.txt\"\n",
        "\n",
        "# Open the file and read its content\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Remove newline characters and append the line to the list\n",
        "        decoded_data = line.replace('\\r\\n', '')\n",
        "        if decoded_data:\n",
        "            geetha_list.append(decoded_data)\n",
        "# Create a DataFrame using pandas with a column named 'Text'\n",
        "geetha_df = pd.DataFrame(geetha_list, columns=['Text'])\n",
        "# Display the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(geetha_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2H-IrITiQq8"
      },
      "outputs": [],
      "source": [
        "def geetha_num_words(x):\n",
        "    return len(str(x).split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E40Zmmg3iQq8",
        "outputId": "f711823a-3d09-435e-a8d6-2fcdc37aab0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of Words' column:\n",
            "                                                  Text  Num of Words\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7\n",
            "1                                 1having to do with\\n             4\n",
            "2    a POIGANT story about a young man who goes off...            12\n",
            "3                                 Synonyms for about\\n             3\n",
            "4                                                   \\n             1\n",
            "..                                                 ...           ...\n",
            "117                                                 \\n             1\n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8\n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8\n",
            "120                                      dreaming ME\\n             2\n",
            "121                             hypnotized, MESMERIZED             2\n",
            "\n",
            "[122 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply the function to the 'Text' column and create a new column 'Num of Words'\n",
        "geetha_df['Num of Words'] = geetha_df['Text'].apply(lambda y: geetha_num_words(y))\n",
        "# Display the DataFrame after adding 'Num of Words' column\n",
        "print(\"\\nDataFrame after adding 'Num of Words' column:\")\n",
        "print(geetha_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rciqQtFqiQq8",
        "outputId": "fa825b39-d3d4-4b3d-a8df-b13440f2746b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of Char' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  \n",
            "0             33  \n",
            "1             19  \n",
            "2             54  \n",
            "3             19  \n",
            "4              1  \n",
            "..           ...  \n",
            "117            1  \n",
            "118           76  \n",
            "119           62  \n",
            "120           12  \n",
            "121           22  \n",
            "\n",
            "[122 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Create a new column 'Num of Char' to store the number of characters in each text\n",
        "geetha_df['Num of Char'] = geetha_df['Text'].str.len()\n",
        "# Display the DataFrame after adding 'Num of Char' column\n",
        "print(\"\\nDataFrame after adding 'Num of Char' column:\")\n",
        "print(geetha_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smTuEXuciQq9"
      },
      "outputs": [],
      "source": [
        "# Function to find the average word length in a text\n",
        "def geetha_avg_word_length(x):\n",
        "    words = x.split()\n",
        "    if len(words) != 0:\n",
        "        return sum(len(word) for word in words) / len(words)\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzJ4y2o9iQq9",
        "outputId": "9065b787-c8c7-4c2a-a4f0-d190f8dc8a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Avg Word Length' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  \n",
            "0             33         3.714286  \n",
            "1             19         3.750000  \n",
            "2             54         3.500000  \n",
            "3             19         5.333333  \n",
            "4              1              NaN  \n",
            "..           ...              ...  \n",
            "117            1              NaN  \n",
            "118           76         8.500000  \n",
            "119           62         6.750000  \n",
            "120           12         5.000000  \n",
            "121           22        10.500000  \n",
            "\n",
            "[122 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply the function to the 'Text' column and create a new column 'Avg Word Length'\n",
        "geetha_df['Avg Word Length'] = geetha_df['Text'].apply(lambda z: geetha_avg_word_length(z))\n",
        "# Display the DataFrame after adding 'Avg Word Length' column\n",
        "print(\"\\nDataFrame after adding 'Avg Word Length' column:\")\n",
        "print(geetha_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txkiu9xaiQq9"
      },
      "outputs": [],
      "source": [
        "# Function to find the number of special characters in a text\n",
        "def geetha_num_special_characters(x):\n",
        "    count = 0\n",
        "    for char in x:\n",
        "        if not(char.isalpha()) and not(char.isdigit()):\n",
        "            count += 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTsFxgQmiQq9"
      },
      "outputs": [],
      "source": [
        "# Apply the function to the 'Text' column and create a new column 'Num of spec char'\n",
        "geetha_df['Num of spec char'] = geetha_df['Text'].apply(lambda y: geetha_num_special_characters(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MJWKjUSiQq-",
        "outputId": "aa8c2ecc-4145-4fe1-aadb-6a9f6a0f3223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of spec char' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  \n",
            "0             33         3.714286                 9  \n",
            "1             19         3.750000                 4  \n",
            "2             54         3.500000                12  \n",
            "3             19         5.333333                 3  \n",
            "4              1              NaN                 1  \n",
            "..           ...              ...               ...  \n",
            "117            1              NaN                 1  \n",
            "118           76         8.500000                15  \n",
            "119           62         6.750000                15  \n",
            "120           12         5.000000                 2  \n",
            "121           22        10.500000                 2  \n",
            "\n",
            "[122 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Display the DataFrame after adding 'Num of spec char' column\n",
        "print(\"\\nDataFrame after adding 'Num of spec char' column:\")\n",
        "print(geetha_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNg7dUsMiQq-"
      },
      "outputs": [],
      "source": [
        " #Function to find the number of numerics in a text\n",
        "geetha_df['Num of num'] = geetha_df['Text'].apply(lambda x: len([word for word in x.split() if word.isdigit()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI0XspHtiQq-",
        "outputId": "b4926789-e1d8-4c25-c1c4-6c46a72b9244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of num' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  Num of num  \n",
            "0             33         3.714286                 9           1  \n",
            "1             19         3.750000                 4           0  \n",
            "2             54         3.500000                12           0  \n",
            "3             19         5.333333                 3           0  \n",
            "4              1              NaN                 1           0  \n",
            "..           ...              ...               ...         ...  \n",
            "117            1              NaN                 1           0  \n",
            "118           76         8.500000                15           0  \n",
            "119           62         6.750000                15           0  \n",
            "120           12         5.000000                 2           0  \n",
            "121           22        10.500000                 2           0  \n",
            "\n",
            "[122 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Display the DataFrame after adding 'Num of num' column\n",
        "print(\"\\nDataFrame after adding 'Num of num' column:\")\n",
        "print(geetha_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIPIgTAMiQq-"
      },
      "outputs": [],
      "source": [
        "# Function to find the number of upper case words in a text\n",
        "geetha_df['Num of upper case words'] = geetha_df['Text'].apply(lambda x: len([word for word in x.split() if word.isupper()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALsEdZY5iQq-",
        "outputId": "ed9614b1-cb22-4cc5-a0ce-a927fb0ca4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of upper case words' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  Num of num  \\\n",
            "0             33         3.714286                 9           1   \n",
            "1             19         3.750000                 4           0   \n",
            "2             54         3.500000                12           0   \n",
            "3             19         5.333333                 3           0   \n",
            "4              1              NaN                 1           0   \n",
            "..           ...              ...               ...         ...   \n",
            "117            1              NaN                 1           0   \n",
            "118           76         8.500000                15           0   \n",
            "119           62         6.750000                15           0   \n",
            "120           12         5.000000                 2           0   \n",
            "121           22        10.500000                 2           0   \n",
            "\n",
            "     Num of upper case words  \n",
            "0                          0  \n",
            "1                          0  \n",
            "2                          1  \n",
            "3                          0  \n",
            "4                          0  \n",
            "..                       ...  \n",
            "117                        0  \n",
            "118                        0  \n",
            "119                        2  \n",
            "120                        1  \n",
            "121                        1  \n",
            "\n",
            "[122 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Display the DataFrame after adding 'Num of upper case words' column\n",
        "print(\"\\nDataFrame after adding 'Num of upper case words' column:\")\n",
        "print(geetha_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV629n1DiQq_"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2bz8KGdiQq_"
      },
      "source": [
        "Rank of most important features here:\n",
        "1. Number of sentences\n",
        "2. Number of Words\n",
        "3. Number of Characters\n",
        "4. Stowords\n",
        "5. Lowercase\n",
        "6. Removal of Punctuation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdqI29ZiQq_"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moBT5dQiiQq_",
        "outputId": "ea8746a8-9eab-4075-9a18-e095a3490a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Documents based on Cosine Similarity:\n",
            "Similarity: 0.9856\n",
            "She is currently working on a project that involves developing a chatbot for customer support using advanced NLP techniques.\n",
            "\n",
            "Similarity: 0.9714\n",
            "Geetha is passionate about using technology to solve real-world problems and make a positive impact.\n",
            "\n",
            "Similarity: 0.9559\n",
            "In her spare time, Geetha enjoys reading books on artificial intelligence and exploring new technologies.\n",
            "\n",
            "Similarity: 0.9519\n",
            "Geetha is a data scientist who specializes in natural language processing and machine learning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "\n",
        "# Different text data\n",
        "geetha = [\n",
        "    \"Geetha is a data scientist who specializes in natural language processing and machine learning.\",\n",
        "    \"In her spare time, Geetha enjoys reading books on artificial intelligence and exploring new technologies.\",\n",
        "    \"Geetha is passionate about using technology to solve real-world problems and make a positive impact.\",\n",
        "    \"She is currently working on a project that involves developing a chatbot for customer support using advanced NLP techniques.\"\n",
        "]\n",
        "\n",
        "# Your query\n",
        "query = \"What projects is Geetha currently working on?\"\n",
        "\n",
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embeddings(text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "    embeddings = outputs.pooler_output.numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Get BERT embeddings for the query and each document\n",
        "query_embedding = get_bert_embeddings(query)\n",
        "geetha_embeddings = [get_bert_embeddings(doc) for doc in geetha]\n",
        "\n",
        "# Calculate cosine similarity between the query and each document\n",
        "similarities = [cosine_similarity(query_embedding, doc_embedding)[0][0] for doc_embedding in geetha_embeddings]\n",
        "\n",
        "# Rank documents based on similarity in descending order\n",
        "ranked_geetha = sorted(zip(geetha, similarities), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the ranked documents\n",
        "print(\"Ranked Documents based on Cosine Similarity:\")\n",
        "for document, similarity in ranked_geetha:\n",
        "    print(f\"Similarity: {similarity:.4f}\\n{document}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Python 3.7.1)",
      "language": "python",
      "name": "py371"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}